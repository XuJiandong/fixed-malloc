# Fixed malloc: a malloc suitable for single threaded, resource constrained environment

## Motivation

There're many malloc implementations out there:

* [jemalloc](https://github.com/jemalloc/jemalloc)
* [tcmalloc](https://github.com/google/tcmalloc)
* [rpmalloc](https://github.com/mjansson/rpmalloc)
* [snmalloc](https://github.com/microsoft/snmalloc)
* [mimalloc](https://github.com/microsoft/mimalloc)
* [buddy-alloc](https://github.com/jjyr/buddy-alloc)
* Most libc implementations also have [malloc](http://git.musl-libc.org/cgit/musl/tree/src/malloc) [implementations](https://sourceware.org/git/?p=newlib-cygwin.git;a=blob;f=newlib/libc/stdlib/_mallocr.c;h=1997b6db15ffc8d9a035af64428b722407ff8278;hb=HEAD) [included](https://sourceware.org/git/?p=glibc.git;a=tree;f=malloc;h=f85e988ef8a15a987c48eb9672735bc8e0003756;hb=HEAD)

Each of the malloc implementations here is built from years of hard work from the brightest minds in the industry. A lot of beautiful algorithms & fascinating engineering tricks are put into them to extract the very last bit of performance from millions of machines running those mallocs. One would naturally wonder: why building yet another malloc implementation?

While building & profiling smart contracts for [Nervos CKB](https://www.nervos.org/), which is essentially a native RISC-V program running under a special OS, we noticed some unique properties shared by CKB smart contracts:

* CKB is a strict single-threaded environment, and will remain so in the foreseeable future. Most modern malloc implementations, put a huge amount of efforts optimizating for multiple-threaded environment, this means a significant amount of work in typical mallocs, is useless for CKB at best, and might contain overheads in certain cases.
* CKB's runtime environment does not have an MMU included, both stack and heap must share the same flat 4MB memory space. There is no syscalls like `mmap` that can help us alleviate memory management issue. Typical use case in CKB smart contracts, is to pre-allocate a fixed buffer, and do heap allocations within this fixed buffer.
* CKB smart contracts are short-lived applications, while each one of them might be repeatedly executed millions of times, each individual execution spans a very short amount of time(typically measured in milliseconds). The runtime environment is also completely discarded after each execution, and rebuilt from zero-filled memory before the next execution.
* The runtime of CKB smart contracts is more crucial than native programs, meaning we would want to go a lot of extra miles to reduce work done within CKB smart contracts, saving **CKB cycles**(in a way, you can think of this as runtime).
* The actual allocations made by CKB smart contracts has a special distribution: a majority of the allocations would be small-size objects, i.e., allocations ranging from 32 bytes to 128 bytes would contribute to 95% or more of all the allocations made. Occasionally, there might be one or two huge buffer(huge here means 32KB or more) made by the smart contracts, but those big allocations can be really rare(less than 5 allocations per execution).

Those properties reveal one unique fact on CKB smart contracts: CKB resembles more like a single-threaded, resource constrained embedded system. In many ways, the tradeoffs are radically different from modern multiple-threaded CPUs with decent MMU as well as a huge amount of memory to spare. Given those differences, the design decisions in a performant malloc implementation for CKB, might also be quite different from modern mallocs for a different machine basis.

That brings to our rationale here: can we build a different malloc implementation, which utilizes CKB's drastically different properties to achieve better performance? This is exactly why we build `fixed-malloc` here.

## Starting Points of Design

Given the above considerations, we started with the following design decision for `fixed-malloc`:

* As the name hinted, `fixed-malloc` does heap allocation from a pre-allocated, static buffer. There might be a few constant-sized static variables used by the malloc library, but all heap allocations generated by the `fixed-malloc`, including bookkeeping data, must reside within the pre-allocated buffer.
* `fixed-malloc` is not thread-safe at all. One must either use it in a strictly single-threade environment, or implement locking mechanisms manually.
* `fixed-malloc` must be optimized for CKB smart contracts' allocation patterns(a huge number of small allocations + rare big allocations).
* Actual bookkeeping work must be reduced at all costs, later we shall see that we leveraged the pre-allocated buffer design to reduce many efforts.

## Design

`fixed-malloc` fundamentally uses a two-layered design:

* An underlying `linear malloc` used to allocate larger, rare memory blocks;
* A `slab malloc` atop used to allocate smaller, frequent memory blocks.

Let's look at each of them individually.

### Linear Malloc

Linear malloc works directly on the pre-allocated static buffer, and is used to allocate large memory blocks. By large memory blocks, we mean that each allocations made by linear malloc, will be rounded up to the nearest 4KB. For example, when allocationg 100,000 bytes via linear malloc, a memory block of 102,400 bytes will be actually allocated. This might be wasteful at first sight, but combined with slab malloc introduced later, the memory waste can be controled, while simplifying the actual algorithm quite a bit.

An actual runtime picture of linear malloc, would look like following:

```
            +-----------__freed_memories<------------------------------------------------+
            |                                                                            |
            |                                                                            |
            | +-----------------------------------+   +-------------------------------+  |
            | |                                   |   |                               |  |
+----+----+-v-++----+---------------------------+-v---+--+---------+-----------+----+-v--+---+
|    |    |    |    |                           |        |         |           |    |        |
| 4K | 4K | 4K | 4K |            ...            |   8K   |   ...   |    12K    | 4K |   8K   |
|    |    |    |    |                           |        |         |           |    |        |
+----+----+----+----+----------^--+-------------+--------+-^--+----+-----------+----+--------+
                               |  |                        |  |
                               |  |                        |  |
                               |  +------------------------+  |
                               |                              |
                        __free_regions<-----------------------+
```

As mentioned above, linear malloc would only allocate memory blocks that are 4KB-aligned. In fact, linear malloc goes one step further: it would require the pre-allocated memory buffer to be aligned as well:

* The pre-allocated memory buffer must start on a 4KB-aligned address
* The size of the pre-allocated memory buffer would be a multiple of 4KB

Simply put, linear malloc works on 4KB-aligned memory everywhere. The careful ones can now deduce that all the memory blocks allocated from linear malloc, would start on 4KB-aligned addresses as well. Later we shall see slab malloc actually takes advantage of this fact to simply memory processing work.

There are 2 pointers used by linear malloc:

* `__free_regions` is a double linked list using the beautiful [c-list](https://github.com/c-util/c-list) that maintains all free regions that can be used to allocate more memory blocks. One might notice that `c-list` is actually an [intrusive double linked list](https://www.data-structures-in-practice.com/intrusive-linked-lists/), the actual linked list pointers are stored within the free regions. Since free regions mean free memory that are used by the actual applications, we are fine to use a few bytes for bookkeeping reasons here.
* `__freed_memories` contains all memory blocks that are already freed. Remember that CKB smart contracts are almost all short-lived programs? One patterns we noticed, is that a lot of `free` operations(or `dealloc` in Rust) are called just before exiting a smart contract. The execution would immediately terminate after exiting the smart contract, and the runtime would be destroyed as well. This means cycles can be reduced if we can manage to perform less work in `free` operations. As a result, linear malloc would simply put the freed memory in the double linked list pointed to by `__freed_memories`(`c-list` ensures that this is an O(1) operation). Only when `malloc` could not allocate more memory blocks, would linear malloc perform the pusedo GC operations that iterates through `__freed_memories`, and merge all already freed memories back into `__free_regions`. So for those rare programs that are really heavy on mallocs, they can still allocate required memories as they need, but for the majority programs, they can reduce the cycle consumptions by doing less work in `free` operations.

It's worth noting that unlike some mallocs, linear malloc does not implement additional spaces before nor after allocated memory blocks. For example, a 12KB block is allocated as shown in the example graph, after rounding the requested size to 12KB (if needed), linear malloc would merely allocate 12KB memory blocks, no memory before or after the memory block is required. On the one hand, this is due to alignment reasons: adding padding memories might either result in a failure to align blocks that start on 4KB boundary, or risk wasting a lot of memory; on the other hand, one might question how linear malloc knows that this very allocated memory block is 12KB when freeing or reallocing.

To solve this issue, linear malloc actually uses the first 4KB of the memory buffer for bookkeeping reasons. Amongst data used for different purposes, a 1024-element `uint8_t` buffer is used to keep track of allocated size for each allocated memory block. Assuming we are allocating the 12KB memory buffer:

0. The memory buffer is initially divided into multiple **pages** of 4KB, as a result, each memory block allocated by linear malloc, will contain a integer number of **pages**. The initial 4KB memory used for bookkeeping reasons, can also be viewed as occupying the first **page**.
1. Based on the starting address of the 12KB buffer, we can calculate the index of the first **page** belonging to this 12KB buffer to allocate. We will also deduce the number of pages for the memory buffer, in this case, 12KB buffer means 3 pages are allocated to this memory buffer. We will then store 3 into the 1024-element `uint8_t` buffer in the bookkeeping page, using the index of the first **page** as index into the 1024-element memory buffer.

There are actually 2 implications of step 1 here:

* The `uint8_t` buffer used to keep memory size only has 1024 elements, meaning linear malloc can only deal with a pre-allocated buffer of 1024 memory pages, or 4MB here. This is more than enough for CKB, but one might want to expand this for more memories. Later version of linear malloc might support more bookkeeping sections for managing more memories.
* A `uint8_t` value is used to store the number of memory pages for an allocated block. This means an allocated block can contains 255 blocks at most, or close to 1MB memory. To overcome this, we actually introduce a small variable encoding scheme here: for memory blocks containing less than 255 blocks, the number of memory pages will be stored directly in the indexed `uint8_t` value, but for larger memory blocks, `0xFF` will be stored in the indexed `uint8_t` value, and the actual number of memory pages will be stored as a `uint32_t` value will be stored in the next 4-byte aligned address succeeding the index of the first memory page. For more details here, see `mark_alloced_pages` and `fetch_alloced_pages` functions in the linear malloc implementation.

Now when freeing or reallocing the allocated memory block, we can reverse the steps:

1. Use the passed in pointer address to calculate the index of the first memory page belonging to this memory block. Or see `ptr_to_page` function for details.
2. Use the index of the first memory page to indexing into the 1024-element `uint8_t` value, if the fetched value is less than `0xFF`, it already contains the number of memory pages, from which we can calculate the size of the memory block.3. Otherwise continue to fetch number of memory pages from the next 4-byte aligned index.

This almost concludes the data structure of linear malloc. Now we can focus on the allocation algorithm of linear malloc. Or simply put: how does linear malloc picks which part in `__free_regions` to use when allocating a new memory block?

#### Double ended allocation algorithm

To reduce memory fragmentation, linear malloc actually allows traversing of `__free_regions` in 2 directions:

* Slab malloc(which will be introduced below) would only allocate memory blocks of 4KB in size, what's more, slab malloc would typically retain the memory for quite some time, and would only free the memory when absolutely memory. As a result, linear malloc would allocate memory for slab malloc starting from the upper memory address downwards.
* Memory blocks allocated directly by linear malloc, are typicall larger in size, and allocations happen more rarely. A program will also decide to free the memory as soon as it is not needed. So linear malloc would allocate large memory blocks from the lower memory address upwards.

Notice this order is also chosen for realloc considerations: slab malloc never realloc its 4KB memory blocks, while a user-level program might start with a 16KB memory, then realloc if necessary. Having 16KB memory blocks in the lower memory address growing upwards, might run into a case where the immediately succeeding 16KB memory space is also unused, in which case we can simply enlarge the original 16KB memory blocks into 32KB memory blocks without further operations such as memcpy, saving us non-trivial cycles.

Note that `c-list` naturally supports traversing the list in both directions, meaning we don't need extra cycles supporting double ended allocations.

Apart from that, linear malloc uses a simple design right now:

1. It traverses `__free_regions` looking for the first section that meets the size requirements, and allocate such a memory block if found;
2. If no existing free region meets the requirements, it traverses `__freed_memories` and merge freed memory blocks back into `__free_regions`;
3. It then retries traversing `__free_regions`, still looking for the first region that has enough space to allocate memory.

There is definitely room for improvements on this algorithm to reduce fragmentation, but we will leave this as future work. Due to the rare allocation needs for larger memory blocks, and the usage of slab malloc, the simple algorithm already works quite well.

### Slab Malloc

```
            +-----------__freed_memories<------------------------------------------------+
            |                                                                            |
            |                                                                            |
            | +-----------------------------------+   +-------------------------------+  |
            | |                                   |   |                               |  |
+----+----+-v-++----+---------------------------+-v---+--+---------+-----------+----+-v--+---+
|    |    |    |    |                           |        |         |           |    |        |
| 4K | 4K | 4K | 4K |            ...            |   8K   |   ...   |    12K    | 4K |   8K   |
|    |    |    |    |                           |        |         |           |    |        |
+----+^-+-+----+-^-++----------^--+-------------+--------+-^--+----+-----------+-^-++--------+
      | |        | |           |  |                        |  |                  | |
      | |        | |           |  |                        |  |                  | |
      | +--------+ |           |  +------------------------+  |                  | |
      |            |           |                              |                  | |
      |            |    __free_regions<-----------------------+                  | |
      |            |                                                             | |
      |            |                                                             | v
    32-byte-slabs<-+                                                        128-byte-slabs
```

Slab malloc is built on top of linear malloc to handle the smaller, frequent allocations. Note that when we are using `fixed-malloc` implementation, we are actually directly using slab malloc here. Linear malloc can be thought as internal implementation details.

Slab malloc, as the name hinted, introduced [slabs](https://en.wikipedia.org/wiki/Slab_allocation), which are 4KB memory blocks that contain smaller blocks(named `memory objects`), each of which is a candidate for slab malloc to return to users. Different from some other slab implementations, here we are fixing the slab memory size, providing different number of underlying smaller objects. For example, a 4KB memory slab, excluding bookkeeping overhead, can provide any of the following:

* 126 32-byte memory objects
* 63 64-byte memory objects
* 31 128-byte memory objects
* 7 512-bytes memory objects
* 3 1024-bytes memory objects

Notice the size of memory objects (named `size class`) to provide via slab malloc, are purely empirical, and might change in the future releases. Right now we are sticking with 32, 64, 128, 512 and 1024 as the size classes for memory objects of which we are providing slabs, since they are the most common ones used by CKB smart contracts.

For each memory object size class here, a double linked list using `c-list` is provided, tracking currently allocated memory slabs. As shown in the above example, we have now allocated 2 slabs for 32-byte objects, and 1 slab for 128-byte objects.

Slab malloc hence work as follows:

1. Given a memory size, slab malloc looks for the smallest size class that is larger or equal to required size. For example, given size 31 or 32, the size class 32 will be used. Given 256, the size class 512 will be used;
2. If no valid size class can be found, e.g., the requested malloc size is 2048 or 100000, slab malloc will call linear malloc directly to allocate the memory block;
3. Given a size class, slab malloc will start traversing the double linked list for the corresponding slab, each slab, is a 4KB memory block containing a fixed 64-byte bookkeeping section, and a series of memory objects to use. The bookkeeping section contains a bitmap indicating memory object usage in the current slab. If an unused memory object in any slab of the current size class can be found, slab malloc will mark the bitmap location for this very memory object as used, and returned the address of the memory object directly;
4. If no unused memory object exists in any slab of the current size class, slab malloc would request a new memory block of 4KB from linear malloc, create a new slab of current size class, attach it to the double linked list, then find an unused memory object in this newly allocated memory slab to return.

In each memory slab, the first 64 bytes are set aside for bookkeeping reasons, storing information such as double linked list pointers, bitmap for memory object usage, size and count of current size class for ease of use, etc. One observation we can deduce then, is that no memory objects can start on a 4KB boundary, this is thus exploited by us to simplify free or realloc handling:

1. If a given memory address starts on 4KB boundary, it must be allocated via linear malloc, we will then pass it to either `fm_lm_free` or `fm_lm_realloc` directly for processing;
2. Otherwise, the memory block must be allocated by slab malloc, we can locate the start of the slab containing current memory object, by rounding the memory address down to a 4KB boundary, and we can start the actual processing from there.

Note we are still maintaining a 16-byte alignment rule here: all memory blocks allocated both by slab malloc directly, and by linear malloc, will start on 16-byte boundary.

As mentioned above, slabs tend to live as long as it can, due to the fact that smaller allocations are more frequent. We will live a slab unchanged even if all memory objects within are unused. This helps 2 scenarios:

* Future allocations might leverage already-initialized slabs
* `free` in slab malloc can do less work

Only when we absolutely need the memory, will we try to free all unused slabs. Feel free to see `fm_sm_malloc` for more details
